{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyTJwdz2qpM3",
        "outputId": "23c4c5a6-6704-462f-fe81-f31f0cee5354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.97      0.62      0.76        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.98      0.81      0.88     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "Confusion Matrix:\n",
            "[[56862     2]\n",
            " [   37    61]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cuml.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data1 = pd.read_csv('data1.csv')\n",
        "\n",
        "# Fix typo: use data1, not dat1\n",
        "X = data1.drop(columns=['Class']).values\n",
        "y = data1['Class'].values  # Correct syntax\n",
        "\n",
        "# Check for at least two classes\n",
        "if len(np.unique(y)) < 2:\n",
        "    raise ValueError(\"SVM requires at least two classes in the target variable.\")\n",
        "\n",
        "# Split the data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Standardize features because SVM are sensitive for feature scale.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# Fit cuML SVM (SVC) on legitimate transactions\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Evaluate using scikit-learn\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cuml.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('data1.csv')"
      ],
      "metadata": {
        "id": "My0y3PUFqUdJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import cudf\n",
        "from cuml.ensemble import RandomForestClassifier\n",
        "from cuml.model_selection import train_test_split, StratifiedKFold\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "\n",
        "\n",
        "def assign_penalty_weights(y_true, y_pred, alpha=2.0, P=45):\n",
        "    y_true = cp.asarray(y_true)\n",
        "    y_pred = cp.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    weights = cp.ones(N)  # default: 1 for all\n",
        "    for i in range(N):\n",
        "        if y_true[i] == 1 and y_pred[i] == 0:  # FN\n",
        "            weights[i] = P\n",
        "    return weights, P\n",
        "\n",
        "# Assume df is a cudf.DataFrame with features and 'Class' as label\n",
        "X = df.drop(columns=['Class'])\n",
        "y = df['Class']\n",
        "\n",
        "# Split into trainval (80%) and final test (20%), stratified\n",
        "X_trainval, X_finaltest, y_trainval, y_finaltest = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Stratified KFold for 5 folds on trainval\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "all_augmented_X, all_augmented_y, all_augmented_weights = [], [], []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X_trainval, y_trainval)):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    # FIX: Convert cupy indices to numpy for iloc\n",
        "    X_train = X_trainval.iloc[train_idx.get()]\n",
        "    X_test = X_trainval.iloc[test_idx.get()]\n",
        "    y_train = y_trainval.iloc[train_idx.get()]\n",
        "    y_test = y_trainval.iloc[test_idx.get()]\n",
        "\n",
        "    # Train XGBoost on legitimate only (class 0)\n",
        "    X_train_legit = X_train[y_train == 0]\n",
        "    y_train_legit = y_train[y_train == 0]\n",
        "    dtrain = xgb.DMatrix(X_train_legit.to_pandas(), label=y_train_legit.to_pandas())\n",
        "    params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'eval_metric': 'logloss',\n",
        "        'verbosity': 0\n",
        "    }\n",
        "    xgb_model = xgb.train(params, dtrain, num_boost_round=50)\n",
        "\n",
        "    # Predict on test set (probabilities)\n",
        "    dtest = xgb.DMatrix(X_test.to_pandas())\n",
        "    y_pred_proba = xgb_model.predict(dtest)\n",
        "    # Outlier detection: classify as fraud (1) if probability < threshold (e.g., 0.1)\n",
        "    threshold = 0.1\n",
        "    y_pred_test_bin = (y_pred_proba < threshold).astype(cp.int32)\n",
        "\n",
        "    # Assign penalties\n",
        "    weights, P = assign_penalty_weights(y_test.values, y_pred_test_bin, alpha=2.0, P=45)\n",
        "\n",
        "    augmented_X, augmented_y, augmented_weights = [], [], []\n",
        "    for i in range(len(X_test)):\n",
        "        xi = X_test.iloc[i]\n",
        "        yi = y_test.iloc[i]\n",
        "        wi = int(cp.round(weights[i]).get())\n",
        "        for _ in range(wi):\n",
        "            augmented_X.append(xi)\n",
        "            augmented_y.append(yi)\n",
        "            augmented_weights.append(wi)\n",
        "    # Add original training data (from this fold)\n",
        "    for i in range(len(X_train)):\n",
        "        augmented_X.append(X_train.iloc[i])\n",
        "        augmented_y.append(y_train.iloc[i])\n",
        "        augmented_weights.append(1.0)\n",
        "\n",
        "# Convert to cudf DataFrame/Series\n",
        "all_augmented_X = cudf.DataFrame(all_augmented_X)\n",
        "all_augmented_y = cudf.Series(all_augmented_y)\n",
        "all_augmented_weights = cp.array(all_augmented_weights)\n",
        "\n",
        "# Train cuML Random Forest on the augmented 80% set\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(all_augmented_X, all_augmented_y, sample_weight=all_augmented_weights)\n",
        "\n",
        "# Evaluate on the untouched final 20% test set\n",
        "y_pred_final = rf.predict(X_finaltest)\n",
        "recall_fraud = recall_score(y_finaltest.to_numpy(), y_pred_final.get(), pos_label=1)\n",
        "print(\"Final fraud recall on untouched test set:\", recall_fraud)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "UeEXQHfQBD6K",
        "outputId": "fb1d819f-41a8-408f-a5aa-1b0065c114d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fc4cf5530ea9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Add original training data (from this fold)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0maugmented_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0maugmented_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0maugmented_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;31m# you only ask for one row.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                     ser = Series._concat(\n\u001b[0;32m--> 522\u001b[0;31m                         \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m                     )\n\u001b[1;32m    524\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;31m# you only ask for one row.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                     ser = Series._concat(\n\u001b[0;32m--> 522\u001b[0;31m                         \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m                     )\n\u001b[1;32m    524\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \"\"\"\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_scalar_or_zero_d_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_columns_by_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m                 \u001b[0mnlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/frame.py\u001b[0m in \u001b[0;36m_get_columns_by_label\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mAkin\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \"\"\"\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_data_like_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_by_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/indexed_frame.py\u001b[0m in \u001b[0;36m_from_data_like_self\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_performance_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_from_data_like_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_data_like_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/frame.py\u001b[0m in \u001b[0;36m_from_data_like_self\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexternal\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_performance_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m_from_data\u001b[0;34m(cls, data, index, columns)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     ) -> Self:\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/indexed_frame.py\u001b[0m in \u001b[0;36m_from_data\u001b[0;34m(cls, data, index)\u001b[0m\n\u001b[1;32m    303\u001b[0m             )\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# out._num_rows requires .index to be defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRangeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     nvtx.annotate(\n\u001b[1;32m     46\u001b[0m                         \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                         \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_color_for_nvtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                         \u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36m_get_color_for_nvtx\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_get_color_for_nvtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all_augmented_X, all_augmented_y, all_augmented_weights to pandas for easy manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Convert cudf to pandas (if not already)\n",
        "X_pd = all_augmented_X.to_pandas()\n",
        "y_pd = all_augmented_y.to_pandas()\n",
        "w_pd = cp.asnumpy(all_augmented_weights)\n",
        "\n",
        "# Round weights to nearest integer (minimum 1)\n",
        "w_pd = np.maximum(np.round(w_pd).astype(int), 1)\n",
        "\n",
        "# Repeat (oversample) each row according to its weight\n",
        "X_oversampled = np.repeat(X_pd.values, w_pd, axis=0)\n",
        "y_oversampled = np.repeat(y_pd.values, w_pd, axis=0)\n",
        "\n",
        "# Convert back to cudf DataFrame/Series for cuML\n",
        "X_oversampled_cudf = cudf.DataFrame(X_oversampled, columns=X_pd.columns)\n",
        "y_oversampled_cudf = cudf.Series(y_oversampled)\n",
        "\n",
        "# Train cuML Random Forest on the oversampled data\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_oversampled_cudf, y_oversampled_cudf)\n",
        "\n",
        "# Evaluate on the untouched final 20% test set\n",
        "y_pred_final = rf.predict(X_finaltest)\n",
        "recall_fraud = recall_score(y_finaltest.to_numpy(), y_pred_final.get(), pos_label=1)\n",
        "print(\"Final fraud recall on untouched test set:\", recall_fraud)\n"
      ],
      "metadata": {
        "id": "l2jk74jqGYx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGboost\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Load the dataset\n",
        "df = pd.read_csv('data1.csv')\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# 2. Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Initialize XGBoost with GPU support\n",
        "model = xgb.XGBClassifier(\n",
        "    tree_method='gpu_hist',\n",
        "    predictor='gpu_predictor',\n",
        "    use_label_encoder=False,\n",
        ")\n",
        "\n",
        "# 4. Train the model\n",
        "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
        "\n",
        "# 5. Predict probabilities and apply custom threshold\n",
        "prob_preds = model.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.25\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 6. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKcW1IBmp5Dr",
        "outputId": "92537a4b-6e6b-4348-da87-18b777211485"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.09428\n",
            "[1]\tvalidation_0-logloss:0.06912\n",
            "[2]\tvalidation_0-logloss:0.05107\n",
            "[3]\tvalidation_0-logloss:0.03799\n",
            "[4]\tvalidation_0-logloss:0.02848\n",
            "[5]\tvalidation_0-logloss:0.02150\n",
            "[6]\tvalidation_0-logloss:0.01634\n",
            "[7]\tvalidation_0-logloss:0.01260\n",
            "[8]\tvalidation_0-logloss:0.00983\n",
            "[9]\tvalidation_0-logloss:0.00782\n",
            "[10]\tvalidation_0-logloss:0.00633\n",
            "[11]\tvalidation_0-logloss:0.00528\n",
            "[12]\tvalidation_0-logloss:0.00449\n",
            "[13]\tvalidation_0-logloss:0.00390\n",
            "[14]\tvalidation_0-logloss:0.00348\n",
            "[15]\tvalidation_0-logloss:0.00314\n",
            "[16]\tvalidation_0-logloss:0.00290\n",
            "[17]\tvalidation_0-logloss:0.00273\n",
            "[18]\tvalidation_0-logloss:0.00262\n",
            "[19]\tvalidation_0-logloss:0.00253\n",
            "[20]\tvalidation_0-logloss:0.00246\n",
            "[21]\tvalidation_0-logloss:0.00242\n",
            "[22]\tvalidation_0-logloss:0.00237\n",
            "[23]\tvalidation_0-logloss:0.00234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:43:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:43:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24]\tvalidation_0-logloss:0.00231\n",
            "[25]\tvalidation_0-logloss:0.00232\n",
            "[26]\tvalidation_0-logloss:0.00230\n",
            "[27]\tvalidation_0-logloss:0.00231\n",
            "[28]\tvalidation_0-logloss:0.00231\n",
            "[29]\tvalidation_0-logloss:0.00234\n",
            "[30]\tvalidation_0-logloss:0.00233\n",
            "[31]\tvalidation_0-logloss:0.00232\n",
            "[32]\tvalidation_0-logloss:0.00234\n",
            "[33]\tvalidation_0-logloss:0.00234\n",
            "[34]\tvalidation_0-logloss:0.00235\n",
            "[35]\tvalidation_0-logloss:0.00235\n",
            "[36]\tvalidation_0-logloss:0.00237\n",
            "[37]\tvalidation_0-logloss:0.00236\n",
            "[38]\tvalidation_0-logloss:0.00237\n",
            "[39]\tvalidation_0-logloss:0.00238\n",
            "[40]\tvalidation_0-logloss:0.00240\n",
            "[41]\tvalidation_0-logloss:0.00240\n",
            "[42]\tvalidation_0-logloss:0.00241\n",
            "[43]\tvalidation_0-logloss:0.00242\n",
            "[44]\tvalidation_0-logloss:0.00243\n",
            "[45]\tvalidation_0-logloss:0.00243\n",
            "[46]\tvalidation_0-logloss:0.00245\n",
            "[47]\tvalidation_0-logloss:0.00246\n",
            "[48]\tvalidation_0-logloss:0.00246\n",
            "[49]\tvalidation_0-logloss:0.00247\n",
            "[50]\tvalidation_0-logloss:0.00247\n",
            "[51]\tvalidation_0-logloss:0.00247\n",
            "[52]\tvalidation_0-logloss:0.00249\n",
            "[53]\tvalidation_0-logloss:0.00249\n",
            "[54]\tvalidation_0-logloss:0.00250\n",
            "[55]\tvalidation_0-logloss:0.00253\n",
            "[56]\tvalidation_0-logloss:0.00253\n",
            "[57]\tvalidation_0-logloss:0.00254\n",
            "[58]\tvalidation_0-logloss:0.00253\n",
            "[59]\tvalidation_0-logloss:0.00253\n",
            "[60]\tvalidation_0-logloss:0.00253\n",
            "[61]\tvalidation_0-logloss:0.00253\n",
            "[62]\tvalidation_0-logloss:0.00255\n",
            "[63]\tvalidation_0-logloss:0.00255\n",
            "[64]\tvalidation_0-logloss:0.00256\n",
            "[65]\tvalidation_0-logloss:0.00255\n",
            "[66]\tvalidation_0-logloss:0.00255\n",
            "[67]\tvalidation_0-logloss:0.00255\n",
            "[68]\tvalidation_0-logloss:0.00255\n",
            "[69]\tvalidation_0-logloss:0.00256\n",
            "[70]\tvalidation_0-logloss:0.00257\n",
            "[71]\tvalidation_0-logloss:0.00258\n",
            "[72]\tvalidation_0-logloss:0.00258\n",
            "[73]\tvalidation_0-logloss:0.00259\n",
            "[74]\tvalidation_0-logloss:0.00260\n",
            "[75]\tvalidation_0-logloss:0.00262\n",
            "[76]\tvalidation_0-logloss:0.00262\n",
            "[77]\tvalidation_0-logloss:0.00263\n",
            "[78]\tvalidation_0-logloss:0.00264\n",
            "[79]\tvalidation_0-logloss:0.00264\n",
            "[80]\tvalidation_0-logloss:0.00265\n",
            "[81]\tvalidation_0-logloss:0.00265\n",
            "[82]\tvalidation_0-logloss:0.00264\n",
            "[83]\tvalidation_0-logloss:0.00265\n",
            "[84]\tvalidation_0-logloss:0.00264\n",
            "[85]\tvalidation_0-logloss:0.00264\n",
            "[86]\tvalidation_0-logloss:0.00265\n",
            "[87]\tvalidation_0-logloss:0.00266\n",
            "[88]\tvalidation_0-logloss:0.00267\n",
            "[89]\tvalidation_0-logloss:0.00268\n",
            "[90]\tvalidation_0-logloss:0.00268\n",
            "[91]\tvalidation_0-logloss:0.00268\n",
            "[92]\tvalidation_0-logloss:0.00268\n",
            "[93]\tvalidation_0-logloss:0.00269\n",
            "[94]\tvalidation_0-logloss:0.00270\n",
            "[95]\tvalidation_0-logloss:0.00269\n",
            "[96]\tvalidation_0-logloss:0.00270\n",
            "[97]\tvalidation_0-logloss:0.00270\n",
            "[98]\tvalidation_0-logloss:0.00271\n",
            "[99]\tvalidation_0-logloss:0.00270\n",
            "Test Accuracy (threshold=0.25): 0.9996\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.96      0.79      0.87        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.98      0.89      0.93     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:43:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Predict probabilities and apply custom threshold\n",
        "prob_preds = model.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.005\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 6. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fyf98D_mrLtw",
        "outputId": "8a2498c2-cad5-4e5f-b2da-c005c7e95b52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy (threshold=0.25): 0.9991\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.67      0.97      0.79        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.83      0.98      0.90     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load data\n",
        "data1 = pd.read_csv('data1.csv')\n",
        "X = data1.drop('Class', axis=1)\n",
        "y = data1['Class']\n",
        "\n",
        "# Train/test split (hold out 20% for final test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# XGBoost DMatrix for cross-validation\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "\n",
        "# Set parameters\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"tree_method\": \"gpu_hist\",  # use 'hist' if no GPU\n",
        "    \"eval_metric\": \"logloss\"\n",
        "}\n",
        "\n",
        "# Cross-validation (5-fold)\n",
        "cv_results = xgb.cv(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=100,\n",
        "    nfold=5,\n",
        "    metrics={\"logloss\"},\n",
        "    early_stopping_rounds=10,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(cv_results.head())\n",
        "\n",
        "# Train final model using best number of rounds from CV\n",
        "best_n = len(cv_results)\n",
        "final_model = xgb.XGBClassifier(\n",
        "    n_estimators=best_n,\n",
        "    tree_method='gpu_hist',\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SQvEQDSp519",
        "outputId": "3740b80e-d12e-4e30-c9f8-8e02e6d69399"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:50:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   train-logloss-mean  train-logloss-std  test-logloss-mean  test-logloss-std\n",
            "0            0.094245           0.000037           0.094410          0.000162\n",
            "1            0.069035           0.000039           0.069253          0.000186\n",
            "2            0.050933           0.000045           0.051197          0.000211\n",
            "3            0.037832           0.000052           0.038135          0.000228\n",
            "4            0.028257           0.000045           0.028614          0.000242\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.91      0.81      0.85        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.95      0.90      0.93     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:50:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:50:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:50:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:50:53] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Predict probabilities and apply custom threshold\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "prob_preds = final_model.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.1\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 6. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db-EU2SUry0m",
        "outputId": "0e99227c-b875-4456-ed63-233632fe4e89"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy (threshold=0.25): 0.9994\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.80      0.86      0.83        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.90      0.93      0.91     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FINAL\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Step 0: Add 'index' column as the first column\n",
        "data = pd.read_csv('data1.csv')\n",
        "data.insert(0, 'index', range(len(data)))  # Add index column at the start\n",
        "\n",
        "# Step 1: Split into train (60%), test1 (20%), test2 (20%) with stratification\n",
        "train, temp = train_test_split(\n",
        "    data, test_size=0.4, stratify=data['Class'], random_state=42\n",
        ")\n",
        "test1, test2 = train_test_split(\n",
        "    temp, test_size=0.5, stratify=temp['Class'], random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Split train into 6 equal, non-overlapping stratified subsets\n",
        "n_subsets = 6\n",
        "skf = StratifiedKFold(n_splits=n_subsets, shuffle=True, random_state= 42)\n",
        "subsets = []\n",
        "for i, (_, idx) in enumerate(skf.split(train, train['Class'])):\n",
        "    subset = data.iloc[idx].copy()\n",
        "    subset['subset'] = f'sub{i+1}'\n",
        "    subsets.append(subset)\n",
        "    #print(f\"Subset {i+1} has {len(subset)} instances.\")\n",
        "    #print(subset['Class'].value_counts())\n",
        "    #print()\n",
        "#subsets[0].head()"
      ],
      "metadata": {
        "id": "5vBCUM-yEWTl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example: Use sub1-sub4 for training, sub6 for evaluation\n",
        "train_subs = pd.concat(subsets[:4], ignore_index=True)\n",
        "val_sub = subsets[5].copy()  # sub6\n",
        "\n",
        "# Step 3: Train XGBoost on sub1-sub4, predict on sub6\n",
        "X_train = train_subs.drop(['Class', 'index', 'subset'], axis=1)\n",
        "y_train = train_subs['Class']\n",
        "X_val = val_sub.drop(['Class', 'index', 'subset'], axis=1)\n",
        "y_val = val_sub['Class']\n",
        "\n",
        "model = xgb.XGBClassifier(tree_method='hist', device='cuda', eval_metric='logloss', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_val)\n",
        "y_proba = model.predict_proba(X_val)[:, 1]  # Probability of fraud (class 1)\n"
      ],
      "metadata": {
        "id": "SlyaNuezHCOz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.1: Classification report, confusion matrix, probabilities\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred, zero_division=0))\n",
        "print(\"\\nFirst 10 predicted probabilities:\", y_proba[:10])\n",
        "\n",
        "# Step 3.2: Find easy frauds (P > T and actual fraud)\n",
        "T = 0.5  # Set your threshold\n",
        "easy_frauds_idx = val_sub[(y_proba > T) & (y_val == 1)].index\n",
        "easy = val_sub.loc[easy_frauds_idx].copy()\n",
        "print(f\"\\nNumber of easy frauds (P > {T} and actual fraud):\", len(easy))\n",
        "\n",
        "# Remove easy frauds from val_sub and update y_val/y_pred/y_proba\n",
        "y_pred = pd.Series(y_pred, index=val_sub.index)\n",
        "y_proba = pd.Series(y_proba, index=val_sub.index)\n",
        "\n",
        "val_sub = val_sub.drop(easy_frauds_idx)\n",
        "y_val = y_val.drop(easy_frauds_idx)\n",
        "\n",
        "y_pred = y_pred.drop(easy_frauds_idx)\n",
        "y_proba = y_proba.drop(easy_frauds_idx)\n",
        "\n",
        "# Step 3.3: Find easy legits (P < 0.1 and actual legit)\n",
        "B = 0.1\n",
        "easy_legits_idx = val_sub[(y_proba < B) & (y_val == 0)].index\n",
        "easy = pd.concat([easy, val_sub.loc[easy_legits_idx]])\n",
        "print(f\"\\nNumber of easy legits (P < {B} and actual legit):\", len(easy_legits_idx ))\n",
        "\n",
        "# Remove easy legits from val_sub and update y_val/y_pred/y_proba\n",
        "val_sub = val_sub.drop(easy_legits_idx)\n",
        "y_val = y_val.drop(easy_legits_idx)\n",
        "y_pred = y_pred.drop(easy_legits_idx)\n",
        "y_proba = y_proba.drop(easy_legits_idx)\n",
        "\n",
        "\n",
        "# Step 3.4: For false negatives (actual fraud, predicted legit), oversample\n",
        "false_negatives_idx = val_sub[(y_val == 1) & (y_pred == 0)].index\n",
        "recall = recall_score(y_val, y_pred, zero_division=0)\n",
        "lamda_1 = 2  # initial value, will adjust later\n",
        "fn_rows = val_sub.loc[false_negatives_idx]\n",
        "fn_probs = pd.Series(y_proba, index=val_sub.index).loc[false_negatives_idx]\n",
        "fn_repeat = np.ceil(recall * lamda_1 / np.maximum(fn_probs, 0.1)).astype(int)\n",
        "fn_oversampled = pd.DataFrame(\n",
        "    np.repeat(fn_rows.values, fn_repeat, axis=0),\n",
        "    columns=fn_rows.columns)\n",
        "\n",
        "# Step 3.5: For false positives (actual legit, predicted fraud), oversample\n",
        "false_positives_idx = val_sub[(y_val == 0) & (y_pred == 1)].index\n",
        "precision = precision_score(y_val, y_pred, zero_division=0)\n",
        "lamda_2 = 2  # initial value, will adjust later\n",
        "fp_rows = val_sub.loc[false_positives_idx]\n",
        "fp_probs = pd.Series(y_proba, index=val_sub.index).loc[false_positives_idx]\n",
        "fp_repeat = np.ceil(precision * lamda_2 / np.maximum(fp_probs, 0.1)).astype(int)\n",
        "fp_oversampled = pd.DataFrame(\n",
        "    np.repeat(fp_rows.values, fp_repeat, axis=0),\n",
        "    columns=fp_rows.columns)\n",
        "\n",
        "# Step 3.6: Adjust lamda_1 and lamda_2 to reach 20% fraud, 80% legit in val_sub\n",
        "def adjust_lambdas(val_sub, fn_oversampled, fp_oversampled, target_fraud_ratio=0.2):\n",
        "    min_lam = 2\n",
        "    lam1, lam2 = min_lam, min_lam\n",
        "    for _ in range(100):  # max 100 iterations\n",
        "        temp = pd.concat([val_sub, fn_oversampled, fp_oversampled])\n",
        "        frauds = temp[temp['Class'] == 1]\n",
        "        legits = temp[temp['Class'] == 0]\n",
        "        total = len(temp)\n",
        "        fraud_ratio = len(frauds) / total if total > 0 else 0\n",
        "        if abs(fraud_ratio - target_fraud_ratio) < 0.01:\n",
        "            break\n",
        "        if fraud_ratio < target_fraud_ratio:\n",
        "            lam1 += 1\n",
        "        else:\n",
        "            lam2 += 1\n",
        "        lam1 = max(lam1, min_lam)\n",
        "        lam2 = max(lam2, min_lam)\n",
        "    return lam1, lam2, temp\n",
        "\n",
        "lamda_1, lamda_2, val_sub_balanced = adjust_lambdas(val_sub, fn_oversampled, fp_oversampled)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2AfS8LL8IJh",
        "outputId": "5a36a9f8-019a-49ac-ca34-593d094c190f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[28397     5]\n",
            " [   11    67]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28402\n",
            "           1       0.93      0.86      0.89        78\n",
            "\n",
            "    accuracy                           1.00     28480\n",
            "   macro avg       0.97      0.93      0.95     28480\n",
            "weighted avg       1.00      1.00      1.00     28480\n",
            "\n",
            "\n",
            "First 10 predicted probabilities: [2.9913022e-07 1.4242125e-05 9.0913227e-06 2.1766514e-06 5.8514360e-07\n",
            " 5.2338709e-07 3.4755087e-07 5.3917188e-06 6.3509378e-06 1.5363554e-06]\n",
            "\n",
            "Number of easy frauds (P > 0.5 and actual fraud): 67\n",
            "\n",
            "Number of easy legits (P < 0.1 and actual legit): 28395\n",
            "\n",
            "Final lamda_1: 2, lamda_2: 102\n",
            "Total samples in balanced sub6: 18\n",
            "Fraud ratio in balanced sub6: 0.611\n",
            "Samples added to sub6 by oversampling: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-b44bb63fe124>:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  temp = pd.concat([val_sub, fn_oversampled, fp_oversampled])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.7: Display results\n",
        "print(f\"\\nFinal lamda_1: {lamda_1}, lamda_2: {lamda_2}\")\n",
        "print(f\"Total samples in balanced sub6: {len(val_sub_balanced)}\")\n",
        "print(f\"Number of frauds left in sub6: {(val_sub['Class'] == 1).sum()}\")\n",
        "print(f\"Number of legits left in sub6: {(val_sub['Class'] == 0).sum()}\")\n",
        "print(f\"Total samples left in sub6: {len(val_sub)}\")\n",
        "print(f\"Fraud ratio in balanced sub6: {val_sub_balanced['Class'].mean():.3f}\")\n",
        "print(f\"Samples added to sub6 by oversampling: {len(val_sub_balanced) - len(val_sub)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb9rUInC-D1L",
        "outputId": "b45ad27f-51c8-4f0b-c862-b42596735171"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final lamda_1: 2, lamda_2: 102\n",
            "Total samples in balanced sub6: 18\n",
            "Number of frauds left in sub6: 11\n",
            "Number of legits left in sub6: 7\n",
            "Total samples left in sub6: 18\n",
            "Fraud ratio in balanced sub6: 0.611\n",
            "Samples added to sub6 by oversampling: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uVj59BwlN7Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Step 0: Add 'index' column as the first column\n",
        "data = pd.read_csv('data1.csv')\n",
        "data.insert(0, 'index', range(len(data)))  # Add index column at the start\n",
        "\n",
        "# Step 1: Split into train (60%), test1 (20%), test2 (20%) with stratification\n",
        "train, temp = train_test_split(\n",
        "    data, test_size=0.4, stratify=data['Class'], random_state=42\n",
        ")\n",
        "test1, test2 = train_test_split(\n",
        "    temp, test_size=0.5, stratify=temp['Class'], random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Split train into 6 equal, non-overlapping stratified subsets\n",
        "n_subsets = 6\n",
        "skf = StratifiedKFold(n_splits=n_subsets, shuffle=True, random_state=42)\n",
        "subsets = []\n",
        "for i, (_, idx) in enumerate(skf.split(train, train['Class'])):\n",
        "    subset = train.iloc[idx].copy()\n",
        "    subset['subset'] = f'sub{i+1}'\n",
        "    subsets.append(subset)\n",
        "\n",
        "# Prepare to collect tough frauds and legits from all validation subsets\n",
        "# Remove easy frauds\n",
        "T = 0.99 #top limit for easy fraud probability\n",
        "# Remove easy legits\n",
        "B = 0.05 # lower limit for fraud probability for easy legit.\n",
        "# Now, apply oversampling with initial lambda values, using per-instance recall/precision\n",
        "lamda_1 = 100\n",
        "lamda_2 = 1\n",
        "fnlt= 0.15 # flase-negative(fraud not cuaght) lower threshol for taugh flase-negative\n",
        "fput= 0.95 # false-positive(legit wrong caught) higher threshold for taugh false-positive.\n",
        "target_fraud_ratio = 0.10\n",
        "\n",
        "all_fn_rows = []\n",
        "all_fn_probs = []\n",
        "all_fn_recalls = []\n",
        "all_fp_rows = []\n",
        "all_fp_probs = []\n",
        "all_fp_precisions = []\n",
        "all_val_sub = []\n",
        "all_hf_rows = []  # To store oversampled hard frauds\n",
        "\n",
        "for val_idx in range(n_subsets):\n",
        "    # Select training and validation subsets\n",
        "    train_subs = pd.concat([subsets[i] for i in range(n_subsets) if i != val_idx], ignore_index=True)\n",
        "    val_sub = subsets[val_idx].copy()\n",
        "\n",
        "    X_train = train_subs.drop(['Class', 'index', 'subset'], axis=1)\n",
        "    y_train = train_subs['Class']\n",
        "    X_val = val_sub.drop(['Class', 'index', 'subset'], axis=1)\n",
        "    y_val = val_sub['Class']\n",
        "\n",
        "    model = xgb.XGBClassifier(tree_method='hist', device='cuda', eval_metric='logloss', random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_proba = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # Calculate recall and precision for this fold (on remaining val_sub)\n",
        "    fold_recall = recall_score(y_val, y_pred, zero_division=0)\n",
        "    fold_precision = precision_score(y_val, y_pred, zero_division=0)\n",
        "\n",
        "    # Remove easy frauds\n",
        "\n",
        "    y_pred = pd.Series(y_pred, index=val_sub.index)\n",
        "    y_proba = pd.Series(y_proba, index=val_sub.index)\n",
        "    easy_frauds_idx = val_sub[(y_proba > T) & (y_val == 1)].index\n",
        "    val_sub = val_sub.drop(easy_frauds_idx)\n",
        "    y_val = y_val.drop(easy_frauds_idx)\n",
        "    y_pred = y_pred.drop(easy_frauds_idx)\n",
        "    y_proba = y_proba.drop(easy_frauds_idx)\n",
        "\n",
        "    # Remove easy legits\n",
        "\n",
        "    easy_legits_idx = val_sub[(y_proba < B) & (y_val == 0)].index\n",
        "    val_sub = val_sub.drop(easy_legits_idx)\n",
        "    y_val = y_val.drop(easy_legits_idx)\n",
        "    y_pred = y_pred.drop(easy_legits_idx)\n",
        "    y_proba = y_proba.drop(easy_legits_idx)\n",
        "\n",
        "\n",
        "\n",
        "    # Collect remaining (tough) false negatives and false positives\n",
        "    false_negatives_idx = val_sub[(y_val == 1) & (y_pred == 0)].index\n",
        "    fn_rows = val_sub.loc[false_negatives_idx].copy()\n",
        "    fn_probs = y_proba.loc[false_negatives_idx]\n",
        "    fn_rows['fold_recall'] = fold_recall  # Store per-fold recall with each row\n",
        "    all_fn_rows.append(fn_rows)\n",
        "    all_fn_probs.append(fn_probs)\n",
        "    all_fn_recalls.append(pd.Series([fold_recall] * len(fn_rows), index=fn_rows.index))\n",
        "\n",
        "    false_positives_idx = val_sub[(y_val == 0) & (y_pred == 1)].index\n",
        "    fp_rows = val_sub.loc[false_positives_idx].copy()\n",
        "    fp_probs = y_proba.loc[false_positives_idx]\n",
        "    fp_rows['fold_precision'] = fold_precision  # Store per-fold precision with each row\n",
        "    all_fp_rows.append(fp_rows)\n",
        "    all_fp_probs.append(fp_probs)\n",
        "    all_fp_precisions.append(pd.Series([fold_precision] * len(fp_rows), index=fp_rows.index))\n",
        "\n",
        "    # Hard frauds: remaining frauds in val_sub that are not FNs\n",
        "    hard_fraud_idx = val_sub[(y_val == 1) & (y_pred == 1)].index\n",
        "    hard_fraud_rows = val_sub.loc[hard_fraud_idx].copy()\n",
        "    hard_fraud_probs = y_proba.loc[hard_fraud_idx]\n",
        "\n",
        "    # Oversample using recall / predicted probability (no lambda)\n",
        "    hf_repeat = np.ceil(fold_recall / np.maximum(hard_fraud_probs, 0.1)).astype(int)\n",
        "    hf_oversampled = pd.DataFrame(\n",
        "        np.repeat(hard_fraud_rows.values, hf_repeat, axis=0),\n",
        "        columns=hard_fraud_rows.columns)\n",
        "    # Store oversampled hard frauds\n",
        "    all_hf_rows.append(hf_oversampled)\n",
        "\n",
        "    # Optionally, collect all remaining val_sub for analysis\n",
        "    all_val_sub.append(val_sub)\n",
        "\n",
        "# Combine all tough cases and their associated probabilities and metrics\n",
        "all_fn_rows = pd.concat(all_fn_rows, ignore_index=True)\n",
        "all_fn_probs = pd.concat(all_fn_probs, ignore_index=True)\n",
        "all_fn_recalls = pd.concat(all_fn_recalls, ignore_index=True)\n",
        "all_fp_rows = pd.concat(all_fp_rows, ignore_index=True)\n",
        "all_fp_probs = pd.concat(all_fp_probs, ignore_index=True)\n",
        "all_fp_precisions = pd.concat(all_fp_precisions, ignore_index=True)\n",
        "all_val_sub = pd.concat(all_val_sub, ignore_index=True)\n",
        "all_hf_rows = pd.concat(all_hf_rows, ignore_index=True)\n",
        "\n",
        "# Now, apply oversampling with initial lambda values, using per-instance recall/precision\n",
        "\n",
        "\n",
        "fn_repeat = np.ceil(all_fn_recalls * lamda_1 / np.maximum(all_fn_probs, 0.1)).astype(int)\n",
        "fn_oversampled = pd.DataFrame(\n",
        "    np.repeat(all_fn_rows.values, fn_repeat, axis=0),\n",
        "    columns=all_fn_rows.columns)\n",
        "\n",
        "fp_repeat = np.ceil(all_fp_precisions * lamda_2 / np.maximum(all_fp_probs, 0.1)).astype(int)\n",
        "fp_oversampled = pd.DataFrame(\n",
        "    np.repeat(all_fp_rows.values, fp_repeat, axis=0),\n",
        "    columns=all_fp_rows.columns)\n",
        "\n",
        "# Oversample using recall / predicted probability (no lambda)\n",
        "hf_repeat = np.ceil(fold_recall / np.maximum(hard_fraud_probs, 0.1)).astype(int)\n",
        "hf_oversampled = pd.DataFrame(\n",
        "    np.repeat(hard_fraud_rows.values, hf_repeat, axis=0),\n",
        "    columns=hard_fraud_rows.columns\n",
        ")\n",
        "\n",
        "# Adjust lambdas to reach 20% fraud, 80% legit\n",
        "def adjust_lambdas(val_sub, fn_oversampled, fp_oversampled, all_hf_rows, all_fn_probs, all_fn_recalls, all_fp_probs, all_fp_precisions, target_fraud_ratio):\n",
        "\n",
        "    lam1, lam2 = lamda_1, lamda_2\n",
        "    for _ in range(100):  # max 100 iterations\n",
        "        temp = pd.concat([val_sub, fn_oversampled, fp_oversampled, all_hf_rows])\n",
        "        frauds = temp[temp['Class'] == 1]\n",
        "        legits = temp[temp['Class'] == 0]\n",
        "        total = len(temp)\n",
        "        fraud_ratio = len(frauds) / total if total > 0 else 0\n",
        "        if abs(fraud_ratio - target_fraud_ratio) < 0.01:\n",
        "            break\n",
        "        if fraud_ratio < target_fraud_ratio:\n",
        "            lam1 += 1\n",
        "        else:\n",
        "            lam2 += 1\n",
        "        lam1 = max(lam1, lamda_1)\n",
        "        lam2 = max(lam2, lamda_2)\n",
        "        # Recalculate oversampled sets with updated lambdas and per-instance recall/precision\n",
        "        fn_repeat = np.ceil(all_fn_recalls * lam1 / np.maximum(all_fn_probs, fnlt)).astype(int)\n",
        "        fn_oversampled = pd.DataFrame(\n",
        "            np.repeat(all_fn_rows.values, fn_repeat, axis=0),\n",
        "            columns=all_fn_rows.columns)\n",
        "        fp_repeat = np.ceil(all_fp_precisions * lam2 / np.maximum(all_fp_probs, fput)).astype(int)\n",
        "        fp_oversampled = pd.DataFrame(\n",
        "            np.repeat(all_fp_rows.values, fp_repeat, axis=0),\n",
        "            columns=all_fp_rows.columns)\n",
        "    temp = pd.concat([val_sub, fn_oversampled, fp_oversampled])\n",
        "    return lam1, lam2, temp\n",
        "\n",
        "lamda_1, lamda_2, val_sub_balanced = adjust_lambdas(\n",
        "    all_val_sub, fn_oversampled, fp_oversampled, all_hf_rows,\n",
        "    all_fn_probs, all_fn_recalls, all_fp_probs, all_fp_precisions,target_fraud_ratio\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0S29JcEacoC3"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count hard frauds and hard legits in all_val_sub (not oversampled)\n",
        "hard_frauds = all_val_sub[all_val_sub['Class'] == 1]\n",
        "hard_legits = all_val_sub[all_val_sub['Class'] == 0]\n",
        "\n",
        "# Count tough frauds (oversampled FNs)\n",
        "tough_frauds_oversampled = len(fn_oversampled)\n",
        "# Count tough positives (oversampled FPs)\n",
        "tough_positives_oversampled = len(fp_oversampled)\n",
        "# Count hard frauds not oversampled\n",
        "hard_frauds_not_oversampled = len(hard_frauds)\n",
        "# Count hard legits not oversampled\n",
        "hard_legits_not_oversampled = len(hard_legits)\n",
        "\n",
        "print(\"\\n==================================\")\n",
        "print(f\"\\nFinal lamda_1: {lamda_1}, lamda_2: {lamda_2}\")\n",
        "print(f\"Total samples remaing in train set after removing easy fraud and\")\n",
        "print(f\"legits ;and adding tough fraud and tough positive: {len(val_sub_balanced)}\")\n",
        "print(f\"Fraud ratio in resultant set from train set: {val_sub_balanced['Class'].mean():.3f}\")\n",
        "print(f\"Samples added by oversampling: {len(val_sub_balanced) - len(all_val_sub)}\")\n",
        "print(f\"Tough fraud samples added by oversampling (False Negatives, FNs): {tough_frauds_oversampled}\")\n",
        "print(f\"Tough positive samples added by oversampling (False Positives, FPs): {tough_positives_oversampled}\")\n",
        "print(f\"Medium fraud samples added by oversampling: {len(all_hf_rows)}\")\n",
        "\n",
        "print(f\"Medium legit samples (not oversampled): {hard_legits_not_oversampled}\")\n",
        "print(final_balanced_df.shape)\n",
        "print(val_sub_balanced['Class'].value_counts())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6KfU1cNOmvQ",
        "outputId": "8ac9fa13-ffa0-4f53-cacc-0f69897b334e"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================\n",
            "\n",
            "Final lamda_1: 100, lamda_2: 101\n",
            "Total samples remaing in train set after removing easy fraud and\n",
            "legits ;and adding tough fraud and tough positive: 31751\n",
            "Fraud ratio in resultant set from train set: 0.946\n",
            "Samples added by oversampling: 31570\n",
            "Tough fraud samples added by oversampling (False Negatives, FNs): 43986\n",
            "Tough positive samples added by oversampling (False Positives, FPs): 28\n",
            "Medium fraud samples added by oversampling: 84\n",
            "Medium legit samples (not oversampled): 46\n",
            "(6151, 33)\n",
            "Class\n",
            "1    30045\n",
            "0     1706\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the final dataset by combining everything\n",
        "final_oversampled_df = pd.concat([val_sub_balanced], ignore_index=True)\n",
        "\n",
        "# Drop helper columns if needed\n",
        "final_oversampled_df  = final_oversampled_df .drop(columns=[col for col in ['fold_recall', 'fold_precision', 'index', 'subset'] if col in final_oversampled_df.columns])\n",
        "\n",
        "# Convert all columns except 'Class' to numeric\n",
        "for col in final_oversampled_df.columns:\n",
        "    df[col] = pd.to_numeric(final_oversampled_df[col], errors='coerce')  # convert, set invalid entries to NaN\n",
        "# Optionally drop rows with NaNs if any were introduced\n",
        "final_oversampled_df = final_oversampled_df.dropna()\n",
        "df_new = final_oversampled_df.copy()"
      ],
      "metadata": {
        "id": "3-cn9Ge6BA--"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "tbhND9LS7VLI"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#down is final ensembled model and up is final data seperation and oversampling"
      ],
      "metadata": {
        "id": "SXjXulmjMWtG"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the final ensemble model\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2. Combine 'train' and 'test1' for Model 1 training\n",
        "train_model1 = pd.concat([train, test1], ignore_index=True)\n",
        "\n",
        "# Separate features (X) and target (y) for Model 1 training\n",
        "X_train_model1 = train_model1.drop('Class', axis=1)\n",
        "y_train_model1 = train_model1['Class']\n",
        "\n",
        "# Separate features (X) and target (y) for Model 2 training (using the original 'train' data after concatenation)\n",
        "train_model2 = pd.concat([df_new, train, test1], ignore_index=True)\n",
        "X_train_model2 = train_model2.drop('Class', axis=1)\n",
        "y_train_model2 = train_model2['Class']\n",
        "\n",
        "# Separate features (X) and target (y) for test2 (final evaluation)\n",
        "X_test2 = test2.drop('Class', axis=1)\n",
        "y_test2 = test2['Class']\n",
        "\n",
        "# Ensure 'index' column is dropped if present in any of the relevant DataFrames\n",
        "for df_to_clean in [X_train_model1, X_train_model2, X_test2]:\n",
        "    if 'index' in df_to_clean.columns:\n",
        "        df_to_clean.drop('index', axis=1, inplace=True)\n",
        "\n",
        "# Ensure data types are suitable for XGBoost and other models\n",
        "X_train_model1 = X_train_model1.astype(float)\n",
        "y_train_model1 = y_train_model1.astype(float)\n",
        "X_train_model2 = X_train_model2.astype(float)\n",
        "y_train_model2 = y_train_model2.astype(float)\n",
        "X_test2 = X_test2.astype(float)\n",
        "y_test2 = y_test2.astype(float)\n",
        "\n",
        "# 3. Initialize and train the first XGBoost model (Model 1) on train_model1\n",
        "model1 = xgb.XGBClassifier(tree_method='hist', device='cuda', eval_metric='logloss', random_state=42)\n",
        "model1.fit(X_train_model1, y_train_model1)\n",
        "\n",
        "# 4. Generate predictions (probabilities) from Model 1 on the data used to train Model 2 (X_train_model2)\n",
        "# This is crucial for avoiding data leakage when training the meta-model\n",
        "model1_preds_for_model2_training = model1.predict_proba(X_train_model2)[:, 1]\n",
        "\n",
        "# 5. Create the dataset for the meta-model's training\n",
        "X_meta_train = pd.DataFrame(model1_preds_for_model2_training, columns=['model1_prob'])\n",
        "y_meta_train = y_train_model2  # The target for the meta-model is the true labels from X_train_model2\n",
        "\n",
        "# 6. Initialize and train the second model (Meta-model) on the meta-model training data\n",
        "meta_model= xgb.XGBClassifier(tree_method='hist', device='cuda', eval_metric='logloss', random_state=42)\n",
        "meta_model.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 7. Generate predictions (probabilities) from Model 1 on test2 (for final evaluation)\n",
        "model1_preds_test2 = model1.predict_proba(X_test2)[:, 1]\n",
        "\n",
        "# 8. Create the dataset for the meta-model's prediction (on test2)\n",
        "X_meta_test = pd.DataFrame(model1_preds_test2, columns=['model1_prob'])\n",
        "\n",
        "# 9. Make final predictions with the Meta-model on test2\n",
        "final_predictions_prob = meta_model.predict_proba(X_meta_test)[:, 1]\n",
        "\n",
        "# Apply your custom threshold for final classification\n",
        "threshold = 0.15 # Or your desired threshold\n",
        "final_predictions_class = (final_predictions_prob > threshold).astype(int)\n",
        "\n",
        "# 10. Evaluate the final ensemble results on test2\n",
        "accuracy = accuracy_score(y_test2, final_predictions_class)\n",
        "print(f\"Final Ensemble Model Accuracy on test2: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print the confusion matrix on test2\n",
        "cm = confusion_matrix(y_test2, final_predictions_class)\n",
        "print(\"\\nConfusion Matrix on test2:\\n\", cm)\n",
        "\n",
        "print(\"\\nClassification Report on test2:\\n\", classification_report(y_test2, final_predictions_class))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyn08eC-MWUZ",
        "outputId": "83208439-587d-499b-97d6-dbe7c52a9d30"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Ensemble Model Accuracy on test2: 0.9996\n",
            "\n",
            "Confusion Matrix on test2:\n",
            " [[56862     1]\n",
            " [   24    75]]\n",
            "\n",
            "Classification Report on test2:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     56863\n",
            "         1.0       0.99      0.76      0.86        99\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.99      0.88      0.93     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (rest of your code for splitting data, training model1 and meta_model)\n",
        "\n",
        "# 7. Generate predictions (probabilities) from Model 1 on test2 (for final evaluation)\n",
        "model1_preds_test2 = model1.predict_proba(X_test2)[:, 1]\n",
        "\n",
        "# 8. Create the dataset for the meta-model's prediction (on test2)\n",
        "X_meta_test = pd.DataFrame(model1_preds_test2, columns=['model1_prob'])\n",
        "\n",
        "threshold = 0.6\n",
        "\n",
        "# 9. Make final predictions with the Meta-model on test2 (you already have this)\n",
        "final_predictions_prob = meta_model.predict_proba(X_meta_test)[:, 1]\n",
        "final_predictions_class = (final_predictions_prob > threshold).astype(int)\n",
        "\n",
        "# 10. Evaluate the final ensemble results on test2\n",
        "# Calculate the AUC score for the ensemble model (meta-model) on test2 data.\n",
        "auc = roc_auc_score(y_test2, meta_model.predict_proba(X_meta_test)[:, 1]) # Use X_meta_test here\n",
        "print(\"AUC:\", auc)\n",
        "\n",
        "# ... (rest of your evaluation code for accuracy, confusion matrix, and classification report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as5HsuLzSKAP",
        "outputId": "ac44a716-5f8e-4a0a-a8eb-6400ac1db3f9"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9619881171065596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply your custom threshold for final classification\n",
        "#threshold = 0.5 # Or your desired threshold\n",
        "final_predictions_class = (final_predictions_prob > threshold).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report on test2:\\n\", classification_report(y_test2, final_predictions_class))\n",
        "\n",
        "\n",
        "# Calculate and print the confusion matrix on test2\n",
        "cm = confusion_matrix(y_test2, (final_predictions_prob > 0.15).astype(int)) # Use 0.15 threshold for confusion matrix\n",
        "print(\"\\nConfusion Matrix on test2:\\n\", cm)\n",
        "\n",
        "print(\"\\nClassification Report on test2:\\n\", classification_report(y_test2, (final_predictions_prob > 0.15).astype(int))) # Use 0.15 threshold for classification report\n",
        "\n",
        "# Calculate the AUC score for the ensemble model (meta-model) on test2 data.\n",
        "# Use a different variable name for the ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test2, final_predictions_prob)  # Renamed 'auc' to 'roc_auc'\n",
        "print(\"ROC AUC:\", roc_auc) # Print 'ROC AUC'\n",
        "\n",
        "# 11. Draw the Precision-Recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test2, final_predictions_prob)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, label=f'Precision-Recall curve (AUC-PR = {auc(recall, precision):.2f})') # Use the original auc function\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve for Ensemble Model\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "HmpODQkHOPBq",
        "outputId": "852ad6db-27b2-4df1-815c-7d0593ba5bd0"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report on test2:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     56863\n",
            "         1.0       0.99      0.76      0.86        99\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.99      0.88      0.93     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "\n",
            "Confusion Matrix on test2:\n",
            " [[56862     1]\n",
            " [   24    75]]\n",
            "\n",
            "Classification Report on test2:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     56863\n",
            "         1.0       0.99      0.76      0.86        99\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.99      0.88      0.93     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "ROC AUC: 0.9619881171065596\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'numpy.float64' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-180-65115cc9c36b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Plot the Precision-Recall curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Precision-Recall curve (AUC-PR = {auc(recall, precision):.2f})'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Use the original auc function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # Import matplotlib\n",
        "\n",
        "# Assuming 'data' is your initial DataFrame\n",
        "\n",
        "# 1. Split data into train, test1, and test2 sets\n",
        "train, temp = train_test_split(\n",
        "    data, test_size=0.4, stratify=data['Class'], random_state=42\n",
        ")\n",
        "test1, test2 = train_test_split(\n",
        "    temp, test_size=0.5, stratify=temp['Class'], random_state=42\n",
        ")\n",
        "\n",
        "# Load your df_new data\n",
        "df_new = pd.read_csv('df_new.csv') # Replace with the actual path to your df_new\n",
        "\n",
        "# 2. Combine 'train' and 'test1' for Model 1 training\n",
        "train_model1 = pd.concat([train, test1], ignore_index=True)\n",
        "\n",
        "# Separate features (X) and target (y) for Model 1 training\n",
        "X_train_model1 = train_model1.drop('Class', axis=1)\n",
        "y_train_model1 = train_model1['Class']\n",
        "\n",
        "# Separate features (X) and target (y) for Model 2 training (using the original 'train' data after concatenation)\n",
        "train_model2 = pd.concat([df_new, train], ignore_index=True)\n",
        "X_train_model2 = train_model2.drop('Class', axis=1)\n",
        "y_train_model2 = train_model2['Class']\n",
        "\n",
        "# Separate features (X) and target (y) for test2 (final evaluation)\n",
        "X_test2 = test2.drop('Class', axis=1)\n",
        "y_test2 = test2['Class']\n",
        "\n",
        "# Ensure 'index' column is dropped if present in any of the relevant DataFrames\n",
        "for df_to_clean in [X_train_model1, X_train_model2, X_test2]:\n",
        "    if 'index' in df_to_clean.columns:\n",
        "        df_to_clean.drop('index', axis=1, inplace=True)\n",
        "\n",
        "# Ensure data types are suitable for XGBoost and other models\n",
        "X_train_model1 = X_train_model1.astype(float)\n",
        "y_train_model1 = y_train_model1.astype(float)\n",
        "X_train_model2 = X_train_model2.astype(float)\n",
        "y_train_model2 = y_train_model2.astype(float)\n",
        "X_test2 = X_test2.astype(float)\n",
        "y_test2 = y_test2.astype(float)\n",
        "\n",
        "# 3. Initialize and train the first XGBoost model (Model 1) on train_model1\n",
        "model1 = xgb.XGBClassifier(tree_method='hist', device='cuda', eval_metric='logloss', random_state=42)\n",
        "model1.fit(X_train_model1, y_train_model1)\n",
        "\n",
        "# 4. Generate predictions (probabilities) from Model 1 on the data used to train Model 2 (X_train_model2)\n",
        "model1_preds_for_model2_training = model1.predict_proba(X_train_model2)[:, 1]\n",
        "\n",
        "# 5. Create the dataset for the meta-model's training\n",
        "X_meta_train = pd.DataFrame(model1_preds_for_model2_training, columns=['model1_prob'])\n",
        "y_meta_train = y_train_model2  # The target for the meta-model is the true labels from X_train_model2\n",
        "\n",
        "# 6. Initialize and train the second model (Meta-model) on the meta-model training data\n",
        "meta_model = LogisticRegression(random_state=42)\n",
        "meta_model.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "# 7. Generate predictions (probabilities) from Model 1 on test2 (for final evaluation)\n",
        "model1_preds_test2 = model1.predict_proba(X_test2)[:, 1]\n",
        "\n",
        "# 8. Create the dataset for the meta-model's prediction (on test2)\n",
        "X_meta_test = pd.DataFrame(model1_preds_test2, columns=['model1_prob'])\n",
        "\n",
        "# 9. Make final predictions with the Meta-model on test2\n",
        "final_predictions_prob = meta_model.predict_proba(X_meta_test)[:, 1]\n",
        "\n",
        "# 10. Evaluate the final ensemble results on test2\n",
        "accuracy = accuracy_score(y_test2, (final_predictions_prob > 0.15).astype(int)) # Use 0.15 threshold for accuracy\n",
        "print(f\"Final Ensemble Model Accuracy on test2: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print the confusion matrix on test2\n",
        "cm = confusion_matrix(y_test2, (final_predictions_prob > 0.15).astype(int)) # Use 0.15 threshold for confusion matrix\n",
        "print(\"\\nConfusion Matrix on test2:\\n\", cm)\n",
        "\n",
        "print(\"\\nClassification Report on test2:\\n\", classification_report(y_test2, (final_predictions_prob > 0.15).astype(int))) # Use 0.15 threshold for classification report\n",
        "\n",
        "# Calculate the AUC score for the ensemble model (meta-model) on test2 data.\n",
        "auc_score = roc_auc_score(y_test2, final_predictions_prob) # Use final_predictions_prob\n",
        "print(\"AUC:\", auc_score)\n",
        "\n",
        "# 11. Draw the Precision-Recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test2, final_predictions_prob) # Use final_predictions_prob\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, label=f'Precision-Recall curve (AUC = {auc(recall, precision):.2f})') # Calculate AUC-PR for the curve\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve for Ensemble Model\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Un6Qb7wJU12D",
        "outputId": "d2259b7d-bd01-43c8-dd36-7101942d24bf"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'df_new.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-7da156535d19>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load your df_new data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_new.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Replace with the actual path to your df_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# 2. Combine 'train' and 'test1' for Model 1 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_new.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#up"
      ],
      "metadata": {
        "id": "pSo9qAd7N-Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have loaded your data into 'train' and 'test2' DataFrames\n",
        "\n",
        "# 1. Load the dataset\n",
        "df = pd.read_csv('data1.csv')\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# 2. Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        "\n",
        "# 3. Initialize XGBoost with GPU support\n",
        "model = xgb.XGBClassifier(tree_method='hist', device='cuda', eval_metric='logloss', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict probabilities and apply custom threshold\n",
        "y_pred = model.predict(X_test)\n",
        "prob_preds = model.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.15\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 5. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))\n"
      ],
      "metadata": {
        "id": "4DJbKJSeIqJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have loaded your data into 'train' and 'test2' DataFrames\n",
        "\n",
        "# 1. Prepare X_train and y_train\n",
        "X_train = train.drop(['Class', 'index'], axis=1).astype(float) # Drop 'Class' and 'index'\n",
        "y_train = train['Class'].astype(float)\n",
        "\n",
        "# 2. Prepare X_test and y_test\n",
        "X_test = test2.drop(['Class', 'index'], axis=1).astype(float)  # Drop 'Class' and 'index'\n",
        "y_test = test2['Class'].astype(float)\n",
        "\n",
        "# 3. Initialize XGBoost with GPU support\n",
        "model = xgb.XGBClassifier(tree_method='hist', device='cuda', eval_metric='logloss', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict probabilities and apply custom threshold\n",
        "y_pred = model.predict(X_test)\n",
        "prob_preds = model.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.15\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 5. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyFAkZoACxPL",
        "outputId": "d80c0c8a-6e2a-4152-fe49-76e86fba3d94"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy (threshold=0.25): 0.9996\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     56863\n",
            "         1.0       0.94      0.82      0.88        99\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.97      0.91      0.94     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.10\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 5. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AP8pUIRCxax",
        "outputId": "e94eb4de-50f5-4ae3-9de0-642993ba4006"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy (threshold=0.25): 0.9995\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     56863\n",
            "         1.0       0.88      0.83      0.85        99\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.94      0.91      0.93     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ed1pfVcjCxhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMbmzxmACxnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qwke8oNxCx1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_oversampled_df.head()\n",
        "#Optional: Save to CSV\n",
        "# final_balanced_df.to_csv(\"balanced_dataset.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "Zxoi0Ui34wM4",
        "outputId": "1e6ed54c-2069-4604-ef14-9a465607972d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Time         V1         V2         V3         V4          V5  \\\n",
              "0  140293.0   0.951025   3.252926  -5.039105   4.632411    3.014501   \n",
              "1   53316.0  -7.752965   0.705763   0.478148   3.985048    3.270238   \n",
              "2   39729.0  -0.964567  -1.643541  -0.187727   1.158253   -2.458336   \n",
              "3   35261.0  -1.236842    1.94939  -1.139733   1.142948   -1.189765   \n",
              "4  166198.0 -35.548539 -31.850484 -48.325589  15.304184 -113.743307   \n",
              "\n",
              "          V6          V7        V8        V9  ...       V21       V22  \\\n",
              "0   -1.34957     0.98094 -1.819539 -2.099049  ...  1.404524 -0.760549   \n",
              "1    1.01761  -10.758946 -8.702424 -0.164677  ... -5.729882  1.216213   \n",
              "2   0.852222    2.785163 -0.303609  0.940006  ...   0.44718  0.536204   \n",
              "3   -1.09756   -2.130852  0.701933 -1.488241  ...  0.234634 -0.887139   \n",
              "4  73.301626  120.589494 -27.34736 -3.872425  ... -21.62012  5.712303   \n",
              "\n",
              "        V23       V24       V25       V26        V27        V28    Amount  \\\n",
              "0  0.358292 -1.185942 -1.286177  0.000365   0.169662   0.108276      0.77   \n",
              "1 -4.698273 -0.296797 -1.700717  0.156541     0.3693   0.075165       0.0   \n",
              "2  1.634061  0.203839  0.218749 -0.221886  -0.308555    -0.1645    776.83   \n",
              "3 -0.140437 -0.467764  0.041665  0.171172   0.865273   0.374717      2.69   \n",
              "4 -1.581098  4.584549  4.554683  3.415636  31.612198 -15.430084  25691.16   \n",
              "\n",
              "  Class  \n",
              "0     1  \n",
              "1     0  \n",
              "2     1  \n",
              "3     0  \n",
              "4     0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0546b305-4d2b-49aa-8ebe-46b54c35bca3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>140293.0</td>\n",
              "      <td>0.951025</td>\n",
              "      <td>3.252926</td>\n",
              "      <td>-5.039105</td>\n",
              "      <td>4.632411</td>\n",
              "      <td>3.014501</td>\n",
              "      <td>-1.34957</td>\n",
              "      <td>0.98094</td>\n",
              "      <td>-1.819539</td>\n",
              "      <td>-2.099049</td>\n",
              "      <td>...</td>\n",
              "      <td>1.404524</td>\n",
              "      <td>-0.760549</td>\n",
              "      <td>0.358292</td>\n",
              "      <td>-1.185942</td>\n",
              "      <td>-1.286177</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.169662</td>\n",
              "      <td>0.108276</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53316.0</td>\n",
              "      <td>-7.752965</td>\n",
              "      <td>0.705763</td>\n",
              "      <td>0.478148</td>\n",
              "      <td>3.985048</td>\n",
              "      <td>3.270238</td>\n",
              "      <td>1.01761</td>\n",
              "      <td>-10.758946</td>\n",
              "      <td>-8.702424</td>\n",
              "      <td>-0.164677</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.729882</td>\n",
              "      <td>1.216213</td>\n",
              "      <td>-4.698273</td>\n",
              "      <td>-0.296797</td>\n",
              "      <td>-1.700717</td>\n",
              "      <td>0.156541</td>\n",
              "      <td>0.3693</td>\n",
              "      <td>0.075165</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39729.0</td>\n",
              "      <td>-0.964567</td>\n",
              "      <td>-1.643541</td>\n",
              "      <td>-0.187727</td>\n",
              "      <td>1.158253</td>\n",
              "      <td>-2.458336</td>\n",
              "      <td>0.852222</td>\n",
              "      <td>2.785163</td>\n",
              "      <td>-0.303609</td>\n",
              "      <td>0.940006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.44718</td>\n",
              "      <td>0.536204</td>\n",
              "      <td>1.634061</td>\n",
              "      <td>0.203839</td>\n",
              "      <td>0.218749</td>\n",
              "      <td>-0.221886</td>\n",
              "      <td>-0.308555</td>\n",
              "      <td>-0.1645</td>\n",
              "      <td>776.83</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35261.0</td>\n",
              "      <td>-1.236842</td>\n",
              "      <td>1.94939</td>\n",
              "      <td>-1.139733</td>\n",
              "      <td>1.142948</td>\n",
              "      <td>-1.189765</td>\n",
              "      <td>-1.09756</td>\n",
              "      <td>-2.130852</td>\n",
              "      <td>0.701933</td>\n",
              "      <td>-1.488241</td>\n",
              "      <td>...</td>\n",
              "      <td>0.234634</td>\n",
              "      <td>-0.887139</td>\n",
              "      <td>-0.140437</td>\n",
              "      <td>-0.467764</td>\n",
              "      <td>0.041665</td>\n",
              "      <td>0.171172</td>\n",
              "      <td>0.865273</td>\n",
              "      <td>0.374717</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166198.0</td>\n",
              "      <td>-35.548539</td>\n",
              "      <td>-31.850484</td>\n",
              "      <td>-48.325589</td>\n",
              "      <td>15.304184</td>\n",
              "      <td>-113.743307</td>\n",
              "      <td>73.301626</td>\n",
              "      <td>120.589494</td>\n",
              "      <td>-27.34736</td>\n",
              "      <td>-3.872425</td>\n",
              "      <td>...</td>\n",
              "      <td>-21.62012</td>\n",
              "      <td>5.712303</td>\n",
              "      <td>-1.581098</td>\n",
              "      <td>4.584549</td>\n",
              "      <td>4.554683</td>\n",
              "      <td>3.415636</td>\n",
              "      <td>31.612198</td>\n",
              "      <td>-15.430084</td>\n",
              "      <td>25691.16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0546b305-4d2b-49aa-8ebe-46b54c35bca3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0546b305-4d2b-49aa-8ebe-46b54c35bca3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0546b305-4d2b-49aa-8ebe-46b54c35bca3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ae895f79-ce82-43f3-afeb-a2e9d1e1d90b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae895f79-ce82-43f3-afeb-a2e9d1e1d90b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ae895f79-ce82-43f3-afeb-a2e9d1e1d90b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XaP-za13CwEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGboost\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Load the dataset\n",
        "\n",
        "\n",
        "\n",
        "# Optionally drop rows with NaNs if any were introduced\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "X = test2.drop('Class', axis=1)\n",
        "y = test2['Class']\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "# 3. Initialize XGBoost with GPU support\n",
        "model = xgb.XGBClassifier(\n",
        "    tree_method='gpu_hist',\n",
        "    predictor='gpu_predictor',\n",
        "    use_label_encoder=False,\n",
        ")\n",
        "\n",
        "# 4. Train the model\n",
        "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
        "\n",
        "# 5. Predict probabilities and apply custom threshold\n",
        "prob_preds = model.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.25\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 6. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))\n"
      ],
      "metadata": {
        "id": "p-7GB06b9rUk"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count hard frauds and hard legits in all_val_sub (not oversampled)\n",
        "hard_frauds = all_val_sub[all_val_sub['Class'] == 1]\n",
        "hard_legits = all_val_sub[all_val_sub['Class'] == 0]\n",
        "\n",
        "# Count tough frauds (oversampled FNs)\n",
        "tough_frauds_oversampled = len(fn_oversampled)\n",
        "# Count tough positives (oversampled FPs)\n",
        "tough_positives_oversampled = len(fp_oversampled)\n",
        "# Count hard frauds not oversampled\n",
        "hard_frauds_not_oversampled = len(hard_frauds)\n",
        "# Count hard legits not oversampled\n",
        "hard_legits_not_oversampled = len(hard_legits)\n",
        "\n",
        "print(\"\\n==================================\")\n",
        "print(f\"\\nFinal lamda_1: {lamda_1}, lamda_2: {lamda_2}\")\n",
        "print(f\"Total samples remaing in train set after removing easy fraud and\")\n",
        "print(f\"legits ;and adding tough fraud and tough positive: {len(val_sub_balanced)}\")\n",
        "print(f\"Fraud ratio in resultant set from train set: {val_sub_balanced['Class'].mean():.3f}\")\n",
        "print(f\"Samples added by oversampling: {len(val_sub_balanced) - len(all_val_sub)}\")\n",
        "print(f\"Tough fraud samples added by oversampling (False Negatives, FNs): {tough_frauds_oversampled}\")\n",
        "print(f\"Tough positive samples added by oversampling (False Positives, FPs): {tough_positives_oversampled}\")\n",
        "print(f\"Medium fraud samples added by oversampling: {len(all_hf_rows)}\")\n",
        "\n",
        "print(f\"Medium legit samples (not oversampled): {hard_legits_not_oversampled}\")\n",
        "print(final_balanced_df.shape)\n",
        "print(val_sub_balanced['Class'].value_counts())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIVFXVBrhu4q",
        "outputId": "7026a9aa-9c39-4a6f-e538-61e046075c78"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================\n",
            "\n",
            "Final lamda_1: 5, lamda_2: 102\n",
            "Total samples remaing in train set after removing easy fraud and\n",
            "legits ;and adding tough fraud and tough positive: 6151\n",
            "Fraud ratio in resultant set from train set: 0.703\n",
            "Samples added by oversampling: 6026\n",
            "Tough fraud samples added by oversampling (False Negatives, FNs): 2210\n",
            "Tough positive samples added by oversampling (False Positives, FPs): 46\n",
            "Medium fraud samples added by oversampling: 28\n",
            "Medium legit samples (not oversampled): 46\n",
            "(6151, 33)\n",
            "Class\n",
            "1    4322\n",
            "0    1829\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1= final_oversampled_df\n",
        "# Convert all columns (except 'Class') to numeric\n",
        "for col in df.columns:\n",
        "\n",
        "  df1[col] = pd.to_numeric(df1[col], errors='coerce')\n",
        "\n",
        "# Drop any rows with NaNs (from conversion)\n",
        "df1 = df1.dropna()\n",
        "\n",
        "import pandas as pd\n",
        "df2 = pd.read_csv('data1.csv')\n",
        "df = pd.concat([df1, df2], ignore_index=True)"
      ],
      "metadata": {
        "id": "lk5r0Ph7pnGG"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6l9CGl8j_qeZ"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cbmbF6j-_1Gz"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGboost\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Load the dataset\n",
        "\n",
        "\n",
        "\n",
        "# Optionally drop rows with NaNs if any were introduced\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# 2. Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Initialize XGBoost with GPU support\n",
        "model = xgb.XGBClassifier(\n",
        "    tree_method='gpu_hist',\n",
        "    predictor='gpu_predictor',\n",
        "    use_label_encoder=False,\n",
        ")\n",
        "\n",
        "# 4. Train the model\n",
        "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
        "\n",
        "# 5. Predict probabilities and apply custom threshold\n",
        "prob_preds = model.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.25\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 6. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNLsOC_o8o0T",
        "outputId": "bd22991d-8244-48c9-86f5-5a6b85fcd5df"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.12036\n",
            "[1]\tvalidation_0-logloss:0.08878\n",
            "[2]\tvalidation_0-logloss:0.06634\n",
            "[3]\tvalidation_0-logloss:0.04998\n",
            "[4]\tvalidation_0-logloss:0.03891\n",
            "[5]\tvalidation_0-logloss:0.03019\n",
            "[6]\tvalidation_0-logloss:0.02375\n",
            "[7]\tvalidation_0-logloss:0.01904\n",
            "[8]\tvalidation_0-logloss:0.01553\n",
            "[9]\tvalidation_0-logloss:0.01284\n",
            "[10]\tvalidation_0-logloss:0.01074\n",
            "[11]\tvalidation_0-logloss:0.00890\n",
            "[12]\tvalidation_0-logloss:0.00773\n",
            "[13]\tvalidation_0-logloss:0.00661\n",
            "[14]\tvalidation_0-logloss:0.00590\n",
            "[15]\tvalidation_0-logloss:0.00531\n",
            "[16]\tvalidation_0-logloss:0.00483\n",
            "[17]\tvalidation_0-logloss:0.00446\n",
            "[18]\tvalidation_0-logloss:0.00404\n",
            "[19]\tvalidation_0-logloss:0.00378\n",
            "[20]\tvalidation_0-logloss:0.00348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:50:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:50:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21]\tvalidation_0-logloss:0.00322\n",
            "[22]\tvalidation_0-logloss:0.00312\n",
            "[23]\tvalidation_0-logloss:0.00286\n",
            "[24]\tvalidation_0-logloss:0.00269\n",
            "[25]\tvalidation_0-logloss:0.00258\n",
            "[26]\tvalidation_0-logloss:0.00249\n",
            "[27]\tvalidation_0-logloss:0.00242\n",
            "[28]\tvalidation_0-logloss:0.00237\n",
            "[29]\tvalidation_0-logloss:0.00231\n",
            "[30]\tvalidation_0-logloss:0.00226\n",
            "[31]\tvalidation_0-logloss:0.00219\n",
            "[32]\tvalidation_0-logloss:0.00213\n",
            "[33]\tvalidation_0-logloss:0.00209\n",
            "[34]\tvalidation_0-logloss:0.00202\n",
            "[35]\tvalidation_0-logloss:0.00196\n",
            "[36]\tvalidation_0-logloss:0.00191\n",
            "[37]\tvalidation_0-logloss:0.00186\n",
            "[38]\tvalidation_0-logloss:0.00184\n",
            "[39]\tvalidation_0-logloss:0.00181\n",
            "[40]\tvalidation_0-logloss:0.00181\n",
            "[41]\tvalidation_0-logloss:0.00179\n",
            "[42]\tvalidation_0-logloss:0.00175\n",
            "[43]\tvalidation_0-logloss:0.00174\n",
            "[44]\tvalidation_0-logloss:0.00173\n",
            "[45]\tvalidation_0-logloss:0.00171\n",
            "[46]\tvalidation_0-logloss:0.00169\n",
            "[47]\tvalidation_0-logloss:0.00168\n",
            "[48]\tvalidation_0-logloss:0.00168\n",
            "[49]\tvalidation_0-logloss:0.00166\n",
            "[50]\tvalidation_0-logloss:0.00165\n",
            "[51]\tvalidation_0-logloss:0.00165\n",
            "[52]\tvalidation_0-logloss:0.00165\n",
            "[53]\tvalidation_0-logloss:0.00164\n",
            "[54]\tvalidation_0-logloss:0.00164\n",
            "[55]\tvalidation_0-logloss:0.00163\n",
            "[56]\tvalidation_0-logloss:0.00163\n",
            "[57]\tvalidation_0-logloss:0.00162\n",
            "[58]\tvalidation_0-logloss:0.00161\n",
            "[59]\tvalidation_0-logloss:0.00161\n",
            "[60]\tvalidation_0-logloss:0.00161\n",
            "[61]\tvalidation_0-logloss:0.00161\n",
            "[62]\tvalidation_0-logloss:0.00161\n",
            "[63]\tvalidation_0-logloss:0.00161\n",
            "[64]\tvalidation_0-logloss:0.00162\n",
            "[65]\tvalidation_0-logloss:0.00163\n",
            "[66]\tvalidation_0-logloss:0.00163\n",
            "[67]\tvalidation_0-logloss:0.00163\n",
            "[68]\tvalidation_0-logloss:0.00163\n",
            "[69]\tvalidation_0-logloss:0.00164\n",
            "[70]\tvalidation_0-logloss:0.00165\n",
            "[71]\tvalidation_0-logloss:0.00165\n",
            "[72]\tvalidation_0-logloss:0.00164\n",
            "[73]\tvalidation_0-logloss:0.00165\n",
            "[74]\tvalidation_0-logloss:0.00164\n",
            "[75]\tvalidation_0-logloss:0.00163\n",
            "[76]\tvalidation_0-logloss:0.00164\n",
            "[77]\tvalidation_0-logloss:0.00164\n",
            "[78]\tvalidation_0-logloss:0.00164\n",
            "[79]\tvalidation_0-logloss:0.00164\n",
            "[80]\tvalidation_0-logloss:0.00165\n",
            "[81]\tvalidation_0-logloss:0.00164\n",
            "[82]\tvalidation_0-logloss:0.00165\n",
            "[83]\tvalidation_0-logloss:0.00164\n",
            "[84]\tvalidation_0-logloss:0.00165\n",
            "[85]\tvalidation_0-logloss:0.00164\n",
            "[86]\tvalidation_0-logloss:0.00164\n",
            "[87]\tvalidation_0-logloss:0.00164\n",
            "[88]\tvalidation_0-logloss:0.00164\n",
            "[89]\tvalidation_0-logloss:0.00165\n",
            "[90]\tvalidation_0-logloss:0.00166\n",
            "[91]\tvalidation_0-logloss:0.00166\n",
            "[92]\tvalidation_0-logloss:0.00166\n",
            "[93]\tvalidation_0-logloss:0.00166\n",
            "[94]\tvalidation_0-logloss:0.00167\n",
            "[95]\tvalidation_0-logloss:0.00167\n",
            "[96]\tvalidation_0-logloss:0.00167\n",
            "[97]\tvalidation_0-logloss:0.00168\n",
            "[98]\tvalidation_0-logloss:0.00168\n",
            "[99]\tvalidation_0-logloss:0.00167\n",
            "Test Accuracy (threshold=0.25): 0.9997\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     57190\n",
            "           1       0.99      0.99      0.99      1002\n",
            "\n",
            "    accuracy                           1.00     58192\n",
            "   macro avg       1.00      0.99      1.00     58192\n",
            "weighted avg       1.00      1.00      1.00     58192\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:50:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExldKGo-8t92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}