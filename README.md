
# âš¡ Model-Driven Oversampling for Fraud Detection
This repository showcases a novel, math-driven, and original oversampling strategy for imbalanced credit card fraud detectionâ€”outperforming all standard projects and benchmarks!

ðŸš€ Key Highlights
**Mathematical Innovation**: Hard-to-classify cases are detected using a custom scoring formula based on model prediction probabilities.

**Custom Oversampling**: Dynamically amplifies the hardest fraud and legitimate samples, not just the rare ones.

**Adaptive Lambda Tuning**: Intelligently balances class ratios without ballooning dataset size.

**Benchmarking**: Surpasses Baseline, SMOTE, ADASYN, and TabNetâ€”see the notebook for results!

**No Data Leakage**: Test set is strictly held out for honest evaluation.


Samples with the highest scores are prioritized for oversampling, ensuring the main model focuses on its biggest weaknesses.

# ðŸ› ï¸ Tech Stack
Python, Pandas, NumPy, Matplotlib

scikit-learn, imbalanced-learn

XGBoost

PyTorch TabNet

# ðŸ’¡ What I Learned
**Math-driven modeling**: It is everything. Focusing on the hardest samples (by prediction error) delivers far better generalization than generic oversampling.

**Originality**: I wonâ€™t shy away from saying I felt elated by what I built. After hundreds of iterations,reading research papers, and over 100+ hours on Google Colab GPU runtime, it was all truly worth it.

**Smart oversampling > brute force**: Adaptive, model-aware duplication creates robust, production-ready fraud detectors.

Runtime: ~5 min on GPU | ~15 hrs on CPU
