{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#libraries and dataset set-up\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"data1.csv\")  # Adjust the path if needed\n",
        "\n",
        "# Drop the 'Time' column\n",
        "data = data.drop(columns=[\"Time\"])\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=[\"Class\"])\n",
        "y = data[\"Class\"]\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = data[\"Class\"])"
      ],
      "metadata": {
        "id": "YsS3YCuY2JLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_kcW0lT_YYW",
        "outputId": "9abaf0da-4303-43b8-9f05-91d5a0fd3e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[56861     3]\n",
            " [   32    66]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.96      0.67      0.79        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.98      0.84      0.90     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#twoclassSVM\n",
        "\n",
        "# Standardize features because SVM are sensitive for feature scale.\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVM with a non-linear kernel\n",
        "svm_model = SVC(kernel='rbf', gamma='scale', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5FkHrKHKXqU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=20,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on Test set\n",
        "rf_pred_test = rf.predict(X_test)\n",
        "rf_pred_proba = rf.predict_proba(X_test)[:, 1]  # for AUC\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\n[RandomForest] Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, rf_pred_test))\n",
        "print(\"[RandomForest] Confusion Matrix on Test Set:\")\n",
        "print(confusion_matrix(y_test, rf_pred_test))\n",
        "\n",
        "# Metrics\n",
        "acc = accuracy_score(y_test, rf_pred_test)  # use predicted labels\n",
        "auc = roc_auc_score(y_test, rf_pred_proba)  # use predicted probabilities\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"AUC:\", auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RruJ305QXpTH",
        "outputId": "8093b325-d4ad-48ea-fde5-8c87f23f1925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  7.8min finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.5s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[RandomForest] Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.95      0.76      0.84        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.97      0.88      0.92     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "[RandomForest] Confusion Matrix on Test Set:\n",
            "[[56860     4]\n",
            " [   24    74]]\n",
            "Accuracy: 0.9995084442259752\n",
            "AUC: 0.9514465412642266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.6s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# ---- Sklearn models ----\n",
        "# Save Random Forest\n",
        "try:\n",
        "    joblib.dump(rf, 'random_forestb_model.pkl')\n",
        "    print(\"[✔] Random Forest saved.\")\n",
        "except NameError:\n",
        "    print(\"[✘] Random Forest model not found.\")"
      ],
      "metadata": {
        "id": "N9lEFG3i_jkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#oneclassSVM\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Extract only non-fraudulent samples (assumes 0 = non-fraud, 1 = fraud)\n",
        "X_train_nonfraud = X_train[y_train == 0]\n",
        "\n",
        "# Train One-Class SVM on non-fraud data only\n",
        "ocsvm = OneClassSVM(gamma='auto', nu=0.01)\n",
        "ocsvm.fit(X_train_nonfraud)\n",
        "\n",
        "# Predict on the full test set\n",
        "y_ocsvm_pred = ocsvm.predict(X_test)\n",
        "\n",
        "# One-Class SVM returns +1 (inlier), -1 (outlier)\n",
        "# Convert to binary: 0 = non-fraud, 1 = fraud\n",
        "y_ocsvm_pred_binary = [0 if x == 1 else 1 for x in y_ocsvm_pred]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\n[One-Class SVM] Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_ocsvm_pred_binary, target_names=[\"Non-Fraud\", \"Fraud\"]))\n",
        "\n",
        "print(\"[One-Class SVM] Confusion Matrix on Test Set:\")\n",
        "print(confusion_matrix(y_test, y_ocsvm_pred_binary, labels=[0, 1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oDVVKphaw82",
        "outputId": "0ac2b237-7c96-4f8c-c34b-febf98b6a1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[One-Class SVM] Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Fraud       1.00      0.95      0.97     56864\n",
            "       Fraud       0.03      0.84      0.05        98\n",
            "\n",
            "    accuracy                           0.95     56962\n",
            "   macro avg       0.51      0.89      0.51     56962\n",
            "weighted avg       1.00      0.95      0.97     56962\n",
            "\n",
            "[One-Class SVM] Confusion Matrix on Test Set:\n",
            "[[53967  2897]\n",
            " [   16    82]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xEyQpeT6_j0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tabNet, transformer based model for tabular data from google\n",
        "!pip -q install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "johp1wKB_j69",
        "outputId": "c61f3417-7df1-4425-8aa7-b264fc2d2e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Tabnet from google optimsed transformer struture for tabular data and imbalanced dataset\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_train_np = X_train.values\n",
        "X_test_np = X_test.values\n",
        "y_train_np = y_train.values\n",
        "y_test_np = y_test.values\n",
        "\n",
        "# Encode labels to 0/1 if needed\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train_np)\n",
        "y_test_enc = le.transform(y_test_np)\n",
        "\n",
        "# Initialize TabNet\n",
        "clf = TabNetClassifier(\n",
        "    n_d=16, n_a=16,\n",
        "    n_steps=5,\n",
        "    gamma=1.5,\n",
        "    lambda_sparse=1e-4,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\": 10, \"gamma\": 0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    verbose=1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Fit TabNet\n",
        "clf.fit(\n",
        "    X_train=X_train_np, y_train=y_train_enc,\n",
        "    eval_set=[(X_test_np, y_test_enc)],\n",
        "    eval_name=['test'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test_np)\n",
        "\n",
        "print(\"\\n[TabNet] Classification Report on Test Set:\")\n",
        "print(classification_report(y_test_enc, y_pred, target_names=[\"Non-Fraud\", \"Fraud\"]))\n",
        "\n",
        "print(\"[TabNet] Confusion Matrix on Test Set:\")\n",
        "print(confusion_matrix(y_test_enc, y_pred, labels=[0, 1]))\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, clf.predict_proba(X_test_np)[:, 1])\n",
        "print(\"AUC:\", roc_auc_score(y_test,clf.predict(X_test_np).ravel()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5SkYk9feyO-",
        "outputId": "4e297e95-5893-49fe-cd50-17f56a55545f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.03318 | test_accuracy: 0.99903 |  0:00:28s\n",
            "epoch 1  | loss: 0.00571 | test_accuracy: 0.99896 |  0:01:00s\n",
            "epoch 2  | loss: 0.00502 | test_accuracy: 0.99893 |  0:01:28s\n",
            "epoch 3  | loss: 0.00445 | test_accuracy: 0.99917 |  0:01:55s\n",
            "epoch 4  | loss: 0.0046  | test_accuracy: 0.99916 |  0:02:22s\n",
            "epoch 5  | loss: 0.00428 | test_accuracy: 0.99916 |  0:02:50s\n",
            "epoch 6  | loss: 0.00402 | test_accuracy: 0.99923 |  0:03:23s\n",
            "epoch 7  | loss: 0.0036  | test_accuracy: 0.99926 |  0:03:51s\n",
            "epoch 8  | loss: 0.00426 | test_accuracy: 0.99923 |  0:04:18s\n",
            "epoch 9  | loss: 0.00398 | test_accuracy: 0.99917 |  0:04:52s\n",
            "epoch 10 | loss: 0.00377 | test_accuracy: 0.99914 |  0:05:19s\n",
            "epoch 11 | loss: 0.00418 | test_accuracy: 0.99905 |  0:05:46s\n",
            "epoch 12 | loss: 0.00414 | test_accuracy: 0.99907 |  0:06:27s\n",
            "epoch 13 | loss: 0.00434 | test_accuracy: 0.99917 |  0:06:54s\n",
            "epoch 14 | loss: 0.00426 | test_accuracy: 0.99898 |  0:07:20s\n",
            "epoch 15 | loss: 0.00412 | test_accuracy: 0.99907 |  0:07:48s\n",
            "epoch 16 | loss: 0.00406 | test_accuracy: 0.99919 |  0:08:16s\n",
            "epoch 17 | loss: 0.004   | test_accuracy: 0.99853 |  0:08:43s\n",
            "\n",
            "Early stopping occurred at epoch 17 with best_epoch = 7 and best_test_accuracy = 0.99926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TabNet] Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Fraud       1.00      1.00      1.00     56864\n",
            "       Fraud       0.77      0.81      0.79        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.89      0.90      0.89     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "[TabNet] Confusion Matrix on Test Set:\n",
            "[[56841    23]\n",
            " [   19    79]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGboost\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Load the dataset\n",
        "df = pd.read_csv('data1.csv')\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# 2. Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Initialize XGBoost with GPU support\n",
        "model = xgb.XGBClassifier(\n",
        "    tree_method='gpu_hist',\n",
        "    predictor='gpu_predictor',\n",
        "    use_label_encoder=False,\n",
        ")\n",
        "\n",
        "# 4. Train the model\n",
        "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
        "\n",
        "# 5. Predict probabilities and apply custom threshold\n",
        "prob_preds = model.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.25\n",
        "class_preds = (prob_preds > threshold).astype(int)\n",
        "\n",
        "# 6. Evaluate the results\n",
        "accuracy = accuracy_score(y_test, class_preds)\n",
        "print(f\"Test Accuracy (threshold=0.25): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, class_preds))\n"
      ],
      "metadata": {
        "id": "TFu5I5k01CZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ab38e7-41ac-4b9b-843d-2a00c255619d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:39:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:39:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.09428\n",
            "[1]\tvalidation_0-logloss:0.06912\n",
            "[2]\tvalidation_0-logloss:0.05107\n",
            "[3]\tvalidation_0-logloss:0.03799\n",
            "[4]\tvalidation_0-logloss:0.02848\n",
            "[5]\tvalidation_0-logloss:0.02150\n",
            "[6]\tvalidation_0-logloss:0.01634\n",
            "[7]\tvalidation_0-logloss:0.01260\n",
            "[8]\tvalidation_0-logloss:0.00983\n",
            "[9]\tvalidation_0-logloss:0.00782\n",
            "[10]\tvalidation_0-logloss:0.00633\n",
            "[11]\tvalidation_0-logloss:0.00528\n",
            "[12]\tvalidation_0-logloss:0.00449\n",
            "[13]\tvalidation_0-logloss:0.00390\n",
            "[14]\tvalidation_0-logloss:0.00348\n",
            "[15]\tvalidation_0-logloss:0.00314\n",
            "[16]\tvalidation_0-logloss:0.00290\n",
            "[17]\tvalidation_0-logloss:0.00273\n",
            "[18]\tvalidation_0-logloss:0.00262\n",
            "[19]\tvalidation_0-logloss:0.00253\n",
            "[20]\tvalidation_0-logloss:0.00246\n",
            "[21]\tvalidation_0-logloss:0.00242\n",
            "[22]\tvalidation_0-logloss:0.00237\n",
            "[23]\tvalidation_0-logloss:0.00234\n",
            "[24]\tvalidation_0-logloss:0.00231\n",
            "[25]\tvalidation_0-logloss:0.00232\n",
            "[26]\tvalidation_0-logloss:0.00230\n",
            "[27]\tvalidation_0-logloss:0.00231\n",
            "[28]\tvalidation_0-logloss:0.00231\n",
            "[29]\tvalidation_0-logloss:0.00234\n",
            "[30]\tvalidation_0-logloss:0.00233\n",
            "[31]\tvalidation_0-logloss:0.00232\n",
            "[32]\tvalidation_0-logloss:0.00234\n",
            "[33]\tvalidation_0-logloss:0.00234\n",
            "[34]\tvalidation_0-logloss:0.00235\n",
            "[35]\tvalidation_0-logloss:0.00235\n",
            "[36]\tvalidation_0-logloss:0.00237\n",
            "[37]\tvalidation_0-logloss:0.00236\n",
            "[38]\tvalidation_0-logloss:0.00237\n",
            "[39]\tvalidation_0-logloss:0.00238\n",
            "[40]\tvalidation_0-logloss:0.00240\n",
            "[41]\tvalidation_0-logloss:0.00240\n",
            "[42]\tvalidation_0-logloss:0.00241\n",
            "[43]\tvalidation_0-logloss:0.00242\n",
            "[44]\tvalidation_0-logloss:0.00243\n",
            "[45]\tvalidation_0-logloss:0.00243\n",
            "[46]\tvalidation_0-logloss:0.00245\n",
            "[47]\tvalidation_0-logloss:0.00246\n",
            "[48]\tvalidation_0-logloss:0.00246\n",
            "[49]\tvalidation_0-logloss:0.00247\n",
            "[50]\tvalidation_0-logloss:0.00247\n",
            "[51]\tvalidation_0-logloss:0.00247\n",
            "[52]\tvalidation_0-logloss:0.00249\n",
            "[53]\tvalidation_0-logloss:0.00249\n",
            "[54]\tvalidation_0-logloss:0.00250\n",
            "[55]\tvalidation_0-logloss:0.00253\n",
            "[56]\tvalidation_0-logloss:0.00253\n",
            "[57]\tvalidation_0-logloss:0.00254\n",
            "[58]\tvalidation_0-logloss:0.00253\n",
            "[59]\tvalidation_0-logloss:0.00253\n",
            "[60]\tvalidation_0-logloss:0.00253\n",
            "[61]\tvalidation_0-logloss:0.00253\n",
            "[62]\tvalidation_0-logloss:0.00255\n",
            "[63]\tvalidation_0-logloss:0.00255\n",
            "[64]\tvalidation_0-logloss:0.00256\n",
            "[65]\tvalidation_0-logloss:0.00255\n",
            "[66]\tvalidation_0-logloss:0.00255\n",
            "[67]\tvalidation_0-logloss:0.00255\n",
            "[68]\tvalidation_0-logloss:0.00255\n",
            "[69]\tvalidation_0-logloss:0.00256\n",
            "[70]\tvalidation_0-logloss:0.00257\n",
            "[71]\tvalidation_0-logloss:0.00258\n",
            "[72]\tvalidation_0-logloss:0.00258\n",
            "[73]\tvalidation_0-logloss:0.00259\n",
            "[74]\tvalidation_0-logloss:0.00260\n",
            "[75]\tvalidation_0-logloss:0.00262\n",
            "[76]\tvalidation_0-logloss:0.00262\n",
            "[77]\tvalidation_0-logloss:0.00263\n",
            "[78]\tvalidation_0-logloss:0.00264\n",
            "[79]\tvalidation_0-logloss:0.00264\n",
            "[80]\tvalidation_0-logloss:0.00265\n",
            "[81]\tvalidation_0-logloss:0.00265\n",
            "[82]\tvalidation_0-logloss:0.00264\n",
            "[83]\tvalidation_0-logloss:0.00265\n",
            "[84]\tvalidation_0-logloss:0.00264\n",
            "[85]\tvalidation_0-logloss:0.00264\n",
            "[86]\tvalidation_0-logloss:0.00265\n",
            "[87]\tvalidation_0-logloss:0.00266\n",
            "[88]\tvalidation_0-logloss:0.00267\n",
            "[89]\tvalidation_0-logloss:0.00268\n",
            "[90]\tvalidation_0-logloss:0.00268\n",
            "[91]\tvalidation_0-logloss:0.00268\n",
            "[92]\tvalidation_0-logloss:0.00268\n",
            "[93]\tvalidation_0-logloss:0.00269\n",
            "[94]\tvalidation_0-logloss:0.00270\n",
            "[95]\tvalidation_0-logloss:0.00269\n",
            "[96]\tvalidation_0-logloss:0.00270\n",
            "[97]\tvalidation_0-logloss:0.00270\n",
            "[98]\tvalidation_0-logloss:0.00271\n",
            "[99]\tvalidation_0-logloss:0.00270\n",
            "Test Accuracy (threshold=0.25): 0.9996\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.96      0.79      0.87        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.98      0.89      0.93     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:39:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:39:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SMOTE with randomforest threshold = 0.25\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Only this import is changed for cuML\n",
        "from cuml.ensemble import RandomForestClassifier as cuRF\n",
        "import numpy as np\n",
        "\n",
        "data1 = pd.read_csv('data1.csv')\n",
        "\n",
        "# Assume data1 is your DataFrame and 'Class' is the label column\n",
        "X = data1.drop('Class', axis=1)\n",
        "y = data1['Class']\n",
        "\n",
        "\n",
        "# Split before SMOTE to avoid data leakage (recommended practice)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43, stratify=y)\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train a classifier (cuML Random Forest on GPU)\n",
        "clf = cuRF(random_state=42)\n",
        "clf.fit(X_train_res.values, y_train_res.values)  # cuML expects numpy arrays\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "y_proba = clf.predict_proba(X_test.values)  # shape: (n_samples, n_classes)\n",
        "\n",
        "# Use threshold = 0.25 for positive class (assuming binary classification and positive class is 1)\n",
        "threshold = 0.25\n",
        "y_pred = (y_proba[:, 1] >= threshold).astype(int)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "tIO8mplCKJn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a202ac-7070-412e-bdd9-671ac9802207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
            "  return init_func(self, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9982619992275552\n",
            "\n",
            "Confusion Matrix:\n",
            " [[56774    90]\n",
            " [    9    89]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.50      0.91      0.64        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.75      0.95      0.82     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cb8kB1QzOGmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}